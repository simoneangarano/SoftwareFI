{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlstac\n",
    "\n",
    "mlstac.download(\n",
    "    snippet=\"isp-uv-es/CloudSEN12Plus\", path=\"data\", split=\"test\", quiet=True\n",
    ")  # use \"all\" to download the entire dataset\n",
    "# Load the ML-STAC collection\n",
    "ds = mlstac.load(snippet=\"data/main.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ds.metadata[\n",
    "    (ds.metadata[\"split\"] == \"test\")\n",
    "    & (ds.metadata[\"label_type\"] == \"high\")\n",
    "    & (ds.metadata[\"proj_shape\"] == 509)\n",
    "][:10]\n",
    "datacube = mlstac.get_data(dataset=subset, quiet=True)\n",
    "datacube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first datapoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "datapoint = datacube[0]\n",
    "datapoint_rgb = np.moveaxis(datapoint[[3, 2, 1]], 0, -1) / 5000\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(datapoint_rgb)\n",
    "ax[0].set_title(\"RGB\")\n",
    "ax[1].imshow(datapoint[13], cmap=\"gray\")\n",
    "ax[1].set_title(\"Human label\")\n",
    "ax[2].imshow(datapoint[14], cmap=\"gray\")\n",
    "ax[2].set_title(\"UnetMobV2 v1.0\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "datapoint = datacube[0]\n",
    "datapoint_rgb = datapoint[[1, 2, 3, 7, 10], ...].astype(np.float32)  # BGRNIR\n",
    "datapoint.shape, datapoint_rgb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Config parsed:\n",
      "name: ghostnetv2_clouds\n",
      "mode: validation\n",
      "ckpt: ckpt/bb_heads_clouds.pth\n",
      "dataset: sentinel\n",
      "num_classes: 3\n",
      "data_dir: ./data\n",
      "device: 0\n",
      "loss: ce\n",
      "clip: 0.05\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr: 0.001\n",
      "optimizer: adamw\n",
      "model: ghostnetv2\n",
      "order: relu-bn\n",
      "affine: False\n",
      "activation: relu6\n",
      "nan: False\n",
      "error_model: random\n",
      "inject_p: 0.1\n",
      "inject_epoch: 0\n",
      "inject_index: 0\n",
      "wd: 0.001\n",
      "rand_aug: None\n",
      "rand_erasing: 0.0\n",
      "mixup_cutmix: False\n",
      "jitter: 0.0\n",
      "label_smooth: 0.0\n",
      "seed: 0\n",
      "comment: Uniform noise [0, epoch). Inj each conv and linear layer. all model. p_c [0.1].\n",
      "num_gpus: 0\n",
      "randrange: 1000\n",
      "csv: ghostnetv2.csv\n",
      "injsite: neuron\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorchfi import core as pfi_core\n",
    "\n",
    "from utils.utils import get_parser, parse_args\n",
    "from utils.data.data_module import CoreDataModule\n",
    "from utils.models.ghostnetv2 import ghostnetv2, GhostNetSS, SegmentationHeadGhostBN\n",
    "from utils.models.LightningModelWrapper import ModelWrapper\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "pl.seed_everything(0, workers=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "parser, config_parser = get_parser()\n",
    "args = parse_args(parser, config_parser, args=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 880 weights\n",
      "torch.Size([1, 3, 512, 512])\n",
      "============================ PYTORCHFI INIT SUMMARY ==============================\n",
      "\n",
      "Layer types allowing injections:\n",
      "----------------------------------------------------------------------------------\n",
      "   - Conv2d\n",
      "   - BatchNorm1d\n",
      "   - BatchNorm2d\n",
      "   - BatchNorm3d\n",
      "\n",
      "Model Info:\n",
      "----------------------------------------------------------------------------------\n",
      "   - Shape of input into the model: (5 512 512 )\n",
      "   - Batch Size: 1\n",
      "   - CUDA Enabled: True\n",
      "\n",
      "Layer Info:\n",
      "----------------------------------------------------------------------------------\n",
      "Layer #       Layer type  Dimensions         Weight Shape         Output Shape\n",
      "----------------------------------------------------------------------------------\n",
      "    0           Conv2d           4        [24, 5, 3, 3]    [1, 24, 256, 256]\n",
      "    1      BatchNorm2d           4                 [24]    [1, 24, 256, 256]\n",
      "    2           Conv2d           4       [12, 24, 1, 1]    [1, 12, 256, 256]\n",
      "    3      BatchNorm2d           4                 [12]    [1, 12, 256, 256]\n",
      "    4           Conv2d           4        [12, 1, 3, 3]    [1, 12, 256, 256]\n",
      "    5      BatchNorm2d           4                 [12]    [1, 12, 256, 256]\n",
      "    6           Conv2d           4       [12, 24, 1, 1]    [1, 12, 256, 256]\n",
      "    7      BatchNorm2d           4                 [12]    [1, 12, 256, 256]\n",
      "    8           Conv2d           4        [12, 1, 3, 3]    [1, 12, 256, 256]\n",
      "    9      BatchNorm2d           4                 [12]    [1, 12, 256, 256]\n",
      "   10           Conv2d           4       [38, 24, 1, 1]    [1, 38, 256, 256]\n",
      "   11      BatchNorm2d           4                 [38]    [1, 38, 256, 256]\n",
      "   12           Conv2d           4        [38, 1, 3, 3]    [1, 38, 256, 256]\n",
      "   13      BatchNorm2d           4                 [38]    [1, 38, 256, 256]\n",
      "   14           Conv2d           4        [76, 1, 3, 3]    [1, 76, 128, 128]\n",
      "   15      BatchNorm2d           4                 [76]    [1, 76, 128, 128]\n",
      "   16           Conv2d           4       [20, 76, 1, 1]    [1, 20, 128, 128]\n",
      "   17      BatchNorm2d           4                 [20]    [1, 20, 128, 128]\n",
      "   18           Conv2d           4        [20, 1, 3, 3]    [1, 20, 128, 128]\n",
      "   19      BatchNorm2d           4                 [20]    [1, 20, 128, 128]\n",
      "   20           Conv2d           4        [24, 1, 3, 3]    [1, 24, 128, 128]\n",
      "   21      BatchNorm2d           4                 [24]    [1, 24, 128, 128]\n",
      "   22           Conv2d           4       [40, 24, 1, 1]    [1, 40, 128, 128]\n",
      "   23      BatchNorm2d           4                 [40]    [1, 40, 128, 128]\n",
      "   24           Conv2d           4       [58, 40, 1, 1]     [1, 116, 64, 64]\n",
      "   25      BatchNorm2d           4                 [58]     [1, 116, 64, 64]\n",
      "   26           Conv2d           4        [58, 1, 3, 3]     [1, 116, 64, 64]\n",
      "   27      BatchNorm2d           4                 [58]     [1, 116, 64, 64]\n",
      "   28           Conv2d           4      [116, 40, 1, 1]     [1, 116, 64, 64]\n",
      "   29      BatchNorm2d           4                [116]     [1, 116, 64, 64]\n",
      "   30           Conv2d           4       [116, 1, 1, 5]    [1, 58, 128, 128]\n",
      "   31      BatchNorm2d           4                [116]    [1, 58, 128, 128]\n",
      "   32           Conv2d           4       [116, 1, 5, 1]    [1, 58, 128, 128]\n",
      "   33      BatchNorm2d           4                [116]    [1, 58, 128, 128]\n",
      "   34           Conv2d           4      [20, 116, 1, 1]    [1, 20, 128, 128]\n",
      "   35      BatchNorm2d           4                 [20]    [1, 20, 128, 128]\n",
      "   36           Conv2d           4        [20, 1, 3, 3]    [1, 20, 128, 128]\n",
      "   37      BatchNorm2d           4                 [20]    [1, 20, 128, 128]\n",
      "   38           Conv2d           4       [58, 40, 1, 1]     [1, 116, 64, 64]\n",
      "   39      BatchNorm2d           4                 [58]     [1, 116, 64, 64]\n",
      "   40           Conv2d           4        [58, 1, 3, 3]     [1, 116, 64, 64]\n",
      "   41      BatchNorm2d           4                 [58]     [1, 116, 64, 64]\n",
      "   42           Conv2d           4      [116, 40, 1, 1]     [1, 116, 64, 64]\n",
      "   43      BatchNorm2d           4                [116]     [1, 116, 64, 64]\n",
      "   44           Conv2d           4       [116, 1, 1, 5]    [1, 58, 128, 128]\n",
      "   45      BatchNorm2d           4                [116]    [1, 58, 128, 128]\n",
      "   46           Conv2d           4       [116, 1, 5, 1]    [1, 58, 128, 128]\n",
      "   47      BatchNorm2d           4                [116]    [1, 58, 128, 128]\n",
      "   48           Conv2d           4       [116, 1, 5, 5]     [1, 116, 64, 64]\n",
      "   49      BatchNorm2d           4                [116]     [1, 116, 64, 64]\n",
      "   50           Conv2d           4      [28, 116, 1, 1]        [1, 28, 1, 1]\n",
      "   51           Conv2d           4      [116, 28, 1, 1]       [1, 116, 1, 1]\n",
      "   52           Conv2d           4      [32, 116, 1, 1]      [1, 32, 64, 64]\n",
      "   53      BatchNorm2d           4                 [32]      [1, 32, 64, 64]\n",
      "   54           Conv2d           4        [32, 1, 3, 3]      [1, 32, 64, 64]\n",
      "   55      BatchNorm2d           4                 [32]      [1, 32, 64, 64]\n",
      "   56           Conv2d           4        [40, 1, 5, 5]      [1, 40, 64, 64]\n",
      "   57      BatchNorm2d           4                 [40]      [1, 40, 64, 64]\n",
      "   58           Conv2d           4       [64, 40, 1, 1]      [1, 64, 64, 64]\n",
      "   59      BatchNorm2d           4                 [64]      [1, 64, 64, 64]\n",
      "   60           Conv2d           4       [96, 64, 1, 1]     [1, 192, 32, 32]\n",
      "   61      BatchNorm2d           4                 [96]     [1, 192, 32, 32]\n",
      "   62           Conv2d           4        [96, 1, 3, 3]     [1, 192, 32, 32]\n",
      "   63      BatchNorm2d           4                 [96]     [1, 192, 32, 32]\n",
      "   64           Conv2d           4      [192, 64, 1, 1]     [1, 192, 32, 32]\n",
      "   65      BatchNorm2d           4                [192]     [1, 192, 32, 32]\n",
      "   66           Conv2d           4       [192, 1, 1, 5]      [1, 96, 64, 64]\n",
      "   67      BatchNorm2d           4                [192]      [1, 96, 64, 64]\n",
      "   68           Conv2d           4       [192, 1, 5, 1]      [1, 96, 64, 64]\n",
      "   69      BatchNorm2d           4                [192]      [1, 96, 64, 64]\n",
      "   70           Conv2d           4      [48, 192, 1, 1]        [1, 48, 1, 1]\n",
      "   71           Conv2d           4      [192, 48, 1, 1]       [1, 192, 1, 1]\n",
      "   72           Conv2d           4      [32, 192, 1, 1]      [1, 32, 64, 64]\n",
      "   73      BatchNorm2d           4                 [32]      [1, 32, 64, 64]\n",
      "   74           Conv2d           4        [32, 1, 3, 3]      [1, 32, 64, 64]\n",
      "   75      BatchNorm2d           4                 [32]      [1, 32, 64, 64]\n",
      "   76           Conv2d           4      [192, 64, 1, 1]     [1, 384, 32, 32]\n",
      "   77      BatchNorm2d           4                [192]     [1, 384, 32, 32]\n",
      "   78           Conv2d           4       [192, 1, 3, 3]     [1, 384, 32, 32]\n",
      "   79      BatchNorm2d           4                [192]     [1, 384, 32, 32]\n",
      "   80           Conv2d           4      [384, 64, 1, 1]     [1, 384, 32, 32]\n",
      "   81      BatchNorm2d           4                [384]     [1, 384, 32, 32]\n",
      "   82           Conv2d           4       [384, 1, 1, 5]     [1, 192, 64, 64]\n",
      "   83      BatchNorm2d           4                [384]     [1, 192, 64, 64]\n",
      "   84           Conv2d           4       [384, 1, 5, 1]     [1, 192, 64, 64]\n",
      "   85      BatchNorm2d           4                [384]     [1, 192, 64, 64]\n",
      "   86           Conv2d           4       [384, 1, 3, 3]     [1, 384, 32, 32]\n",
      "   87      BatchNorm2d           4                [384]     [1, 384, 32, 32]\n",
      "   88           Conv2d           4      [64, 384, 1, 1]      [1, 64, 32, 32]\n",
      "   89      BatchNorm2d           4                 [64]      [1, 64, 32, 32]\n",
      "   90           Conv2d           4        [64, 1, 3, 3]      [1, 64, 32, 32]\n",
      "   91      BatchNorm2d           4                 [64]      [1, 64, 32, 32]\n",
      "   92           Conv2d           4        [64, 1, 3, 3]      [1, 64, 32, 32]\n",
      "   93      BatchNorm2d           4                 [64]      [1, 64, 32, 32]\n",
      "   94           Conv2d           4      [128, 64, 1, 1]     [1, 128, 32, 32]\n",
      "   95      BatchNorm2d           4                [128]     [1, 128, 32, 32]\n",
      "   96           Conv2d           4     [160, 128, 1, 1]     [1, 320, 16, 16]\n",
      "   97      BatchNorm2d           4                [160]     [1, 320, 16, 16]\n",
      "   98           Conv2d           4       [160, 1, 3, 3]     [1, 320, 16, 16]\n",
      "   99      BatchNorm2d           4                [160]     [1, 320, 16, 16]\n",
      "  100           Conv2d           4     [320, 128, 1, 1]     [1, 320, 16, 16]\n",
      "  101      BatchNorm2d           4                [320]     [1, 320, 16, 16]\n",
      "  102           Conv2d           4       [320, 1, 1, 5]     [1, 160, 32, 32]\n",
      "  103      BatchNorm2d           4                [320]     [1, 160, 32, 32]\n",
      "  104           Conv2d           4       [320, 1, 5, 1]     [1, 160, 32, 32]\n",
      "  105      BatchNorm2d           4                [320]     [1, 160, 32, 32]\n",
      "  106           Conv2d           4      [64, 320, 1, 1]      [1, 64, 32, 32]\n",
      "  107      BatchNorm2d           4                 [64]      [1, 64, 32, 32]\n",
      "  108           Conv2d           4        [64, 1, 3, 3]      [1, 64, 32, 32]\n",
      "  109      BatchNorm2d           4                 [64]      [1, 64, 32, 32]\n",
      "  110           Conv2d           4     [148, 128, 1, 1]     [1, 296, 16, 16]\n",
      "  111      BatchNorm2d           4                [148]     [1, 296, 16, 16]\n",
      "  112           Conv2d           4       [148, 1, 3, 3]     [1, 296, 16, 16]\n",
      "  113      BatchNorm2d           4                [148]     [1, 296, 16, 16]\n",
      "  114           Conv2d           4     [296, 128, 1, 1]     [1, 296, 16, 16]\n",
      "  115      BatchNorm2d           4                [296]     [1, 296, 16, 16]\n",
      "  116           Conv2d           4       [296, 1, 1, 5]     [1, 148, 32, 32]\n",
      "  117      BatchNorm2d           4                [296]     [1, 148, 32, 32]\n",
      "  118           Conv2d           4       [296, 1, 5, 1]     [1, 148, 32, 32]\n",
      "  119      BatchNorm2d           4                [296]     [1, 148, 32, 32]\n",
      "  120           Conv2d           4      [64, 296, 1, 1]      [1, 64, 32, 32]\n",
      "  121      BatchNorm2d           4                 [64]      [1, 64, 32, 32]\n",
      "  122           Conv2d           4        [64, 1, 3, 3]      [1, 64, 32, 32]\n",
      "  123      BatchNorm2d           4                 [64]      [1, 64, 32, 32]\n",
      "  124           Conv2d           4     [148, 128, 1, 1]     [1, 296, 16, 16]\n",
      "  125      BatchNorm2d           4                [148]     [1, 296, 16, 16]\n",
      "  126           Conv2d           4       [148, 1, 3, 3]     [1, 296, 16, 16]\n",
      "  127      BatchNorm2d           4                [148]     [1, 296, 16, 16]\n",
      "  128           Conv2d           4     [296, 128, 1, 1]     [1, 296, 16, 16]\n",
      "  129      BatchNorm2d           4                [296]     [1, 296, 16, 16]\n",
      "  130           Conv2d           4       [296, 1, 1, 5]     [1, 148, 32, 32]\n",
      "  131      BatchNorm2d           4                [296]     [1, 148, 32, 32]\n",
      "  132           Conv2d           4       [296, 1, 5, 1]     [1, 148, 32, 32]\n",
      "  133      BatchNorm2d           4                [296]     [1, 148, 32, 32]\n",
      "  134           Conv2d           4      [64, 296, 1, 1]      [1, 64, 32, 32]\n",
      "  135      BatchNorm2d           4                 [64]      [1, 64, 32, 32]\n",
      "  136           Conv2d           4        [64, 1, 3, 3]      [1, 64, 32, 32]\n",
      "  137      BatchNorm2d           4                 [64]      [1, 64, 32, 32]\n",
      "  138           Conv2d           4     [384, 128, 1, 1]     [1, 768, 16, 16]\n",
      "  139      BatchNorm2d           4                [384]     [1, 768, 16, 16]\n",
      "  140           Conv2d           4       [384, 1, 3, 3]     [1, 768, 16, 16]\n",
      "  141      BatchNorm2d           4                [384]     [1, 768, 16, 16]\n",
      "  142           Conv2d           4     [768, 128, 1, 1]     [1, 768, 16, 16]\n",
      "  143      BatchNorm2d           4                [768]     [1, 768, 16, 16]\n",
      "  144           Conv2d           4       [768, 1, 1, 5]     [1, 384, 32, 32]\n",
      "  145      BatchNorm2d           4                [768]     [1, 384, 32, 32]\n",
      "  146           Conv2d           4       [768, 1, 5, 1]     [1, 384, 32, 32]\n",
      "  147      BatchNorm2d           4                [768]     [1, 384, 32, 32]\n",
      "  148           Conv2d           4     [192, 768, 1, 1]       [1, 192, 1, 1]\n",
      "  149           Conv2d           4     [768, 192, 1, 1]       [1, 768, 1, 1]\n",
      "  150           Conv2d           4      [90, 768, 1, 1]      [1, 90, 32, 32]\n",
      "  151      BatchNorm2d           4                 [90]      [1, 90, 32, 32]\n",
      "  152           Conv2d           4        [90, 1, 3, 3]      [1, 90, 32, 32]\n",
      "  153      BatchNorm2d           4                 [90]      [1, 90, 32, 32]\n",
      "  154           Conv2d           4       [128, 1, 3, 3]     [1, 128, 32, 32]\n",
      "  155      BatchNorm2d           4                [128]     [1, 128, 32, 32]\n",
      "  156           Conv2d           4     [180, 128, 1, 1]     [1, 180, 32, 32]\n",
      "  157      BatchNorm2d           4                [180]     [1, 180, 32, 32]\n",
      "  158           Conv2d           4     [538, 180, 1, 1]    [1, 1076, 16, 16]\n",
      "  159      BatchNorm2d           4                [538]    [1, 1076, 16, 16]\n",
      "  160           Conv2d           4       [538, 1, 3, 3]    [1, 1076, 16, 16]\n",
      "  161      BatchNorm2d           4                [538]    [1, 1076, 16, 16]\n",
      "  162           Conv2d           4    [1076, 180, 1, 1]    [1, 1076, 16, 16]\n",
      "  163      BatchNorm2d           4               [1076]    [1, 1076, 16, 16]\n",
      "  164           Conv2d           4      [1076, 1, 1, 5]     [1, 538, 32, 32]\n",
      "  165      BatchNorm2d           4               [1076]     [1, 538, 32, 32]\n",
      "  166           Conv2d           4      [1076, 1, 5, 1]     [1, 538, 32, 32]\n",
      "  167      BatchNorm2d           4               [1076]     [1, 538, 32, 32]\n",
      "  168           Conv2d           4    [268, 1076, 1, 1]       [1, 268, 1, 1]\n",
      "  169           Conv2d           4    [1076, 268, 1, 1]      [1, 1076, 1, 1]\n",
      "  170           Conv2d           4     [90, 1076, 1, 1]      [1, 90, 32, 32]\n",
      "  171      BatchNorm2d           4                 [90]      [1, 90, 32, 32]\n",
      "  172           Conv2d           4        [90, 1, 3, 3]      [1, 90, 32, 32]\n",
      "  173      BatchNorm2d           4                 [90]      [1, 90, 32, 32]\n",
      "  174           Conv2d           4     [538, 180, 1, 1]    [1, 1076, 16, 16]\n",
      "  175      BatchNorm2d           4                [538]    [1, 1076, 16, 16]\n",
      "  176           Conv2d           4       [538, 1, 3, 3]    [1, 1076, 16, 16]\n",
      "  177      BatchNorm2d           4                [538]    [1, 1076, 16, 16]\n",
      "  178           Conv2d           4    [1076, 180, 1, 1]    [1, 1076, 16, 16]\n",
      "  179      BatchNorm2d           4               [1076]    [1, 1076, 16, 16]\n",
      "  180           Conv2d           4      [1076, 1, 1, 5]     [1, 538, 32, 32]\n",
      "  181      BatchNorm2d           4               [1076]     [1, 538, 32, 32]\n",
      "  182           Conv2d           4      [1076, 1, 5, 1]     [1, 538, 32, 32]\n",
      "  183      BatchNorm2d           4               [1076]     [1, 538, 32, 32]\n",
      "  184           Conv2d           4      [1076, 1, 5, 5]    [1, 1076, 16, 16]\n",
      "  185      BatchNorm2d           4               [1076]    [1, 1076, 16, 16]\n",
      "  186           Conv2d           4    [268, 1076, 1, 1]       [1, 268, 1, 1]\n",
      "  187           Conv2d           4    [1076, 268, 1, 1]      [1, 1076, 1, 1]\n",
      "  188           Conv2d           4    [128, 1076, 1, 1]     [1, 128, 16, 16]\n",
      "  189      BatchNorm2d           4                [128]     [1, 128, 16, 16]\n",
      "  190           Conv2d           4       [128, 1, 3, 3]     [1, 128, 16, 16]\n",
      "  191      BatchNorm2d           4                [128]     [1, 128, 16, 16]\n",
      "  192           Conv2d           4       [180, 1, 5, 5]     [1, 180, 16, 16]\n",
      "  193      BatchNorm2d           4                [180]     [1, 180, 16, 16]\n",
      "  194           Conv2d           4     [256, 180, 1, 1]     [1, 256, 16, 16]\n",
      "  195      BatchNorm2d           4                [256]     [1, 256, 16, 16]\n",
      "  196           Conv2d           4     [768, 256, 1, 1]      [1, 1536, 8, 8]\n",
      "  197      BatchNorm2d           4                [768]      [1, 1536, 8, 8]\n",
      "  198           Conv2d           4       [768, 1, 3, 3]      [1, 1536, 8, 8]\n",
      "  199      BatchNorm2d           4                [768]      [1, 1536, 8, 8]\n",
      "  200           Conv2d           4    [1536, 256, 1, 1]      [1, 1536, 8, 8]\n",
      "  201      BatchNorm2d           4               [1536]      [1, 1536, 8, 8]\n",
      "  202           Conv2d           4      [1536, 1, 1, 5]     [1, 768, 16, 16]\n",
      "  203      BatchNorm2d           4               [1536]     [1, 768, 16, 16]\n",
      "  204           Conv2d           4      [1536, 1, 5, 1]     [1, 768, 16, 16]\n",
      "  205      BatchNorm2d           4               [1536]     [1, 768, 16, 16]\n",
      "  206           Conv2d           4    [128, 1536, 1, 1]     [1, 128, 16, 16]\n",
      "  207      BatchNorm2d           4                [128]     [1, 128, 16, 16]\n",
      "  208           Conv2d           4       [128, 1, 3, 3]     [1, 128, 16, 16]\n",
      "  209      BatchNorm2d           4                [128]     [1, 128, 16, 16]\n",
      "  210           Conv2d           4     [768, 256, 1, 1]      [1, 1536, 8, 8]\n",
      "  211      BatchNorm2d           4                [768]      [1, 1536, 8, 8]\n",
      "  212           Conv2d           4       [768, 1, 3, 3]      [1, 1536, 8, 8]\n",
      "  213      BatchNorm2d           4                [768]      [1, 1536, 8, 8]\n",
      "  214           Conv2d           4    [1536, 256, 1, 1]      [1, 1536, 8, 8]\n",
      "  215      BatchNorm2d           4               [1536]      [1, 1536, 8, 8]\n",
      "  216           Conv2d           4      [1536, 1, 1, 5]     [1, 768, 16, 16]\n",
      "  217      BatchNorm2d           4               [1536]     [1, 768, 16, 16]\n",
      "  218           Conv2d           4      [1536, 1, 5, 1]     [1, 768, 16, 16]\n",
      "  219      BatchNorm2d           4               [1536]     [1, 768, 16, 16]\n",
      "  220           Conv2d           4    [384, 1536, 1, 1]       [1, 384, 1, 1]\n",
      "  221           Conv2d           4    [1536, 384, 1, 1]      [1, 1536, 1, 1]\n",
      "  222           Conv2d           4    [128, 1536, 1, 1]     [1, 128, 16, 16]\n",
      "  223      BatchNorm2d           4                [128]     [1, 128, 16, 16]\n",
      "  224           Conv2d           4       [128, 1, 3, 3]     [1, 128, 16, 16]\n",
      "  225      BatchNorm2d           4                [128]     [1, 128, 16, 16]\n",
      "  226           Conv2d           4     [768, 256, 1, 1]      [1, 1536, 8, 8]\n",
      "  227      BatchNorm2d           4                [768]      [1, 1536, 8, 8]\n",
      "  228           Conv2d           4       [768, 1, 3, 3]      [1, 1536, 8, 8]\n",
      "  229      BatchNorm2d           4                [768]      [1, 1536, 8, 8]\n",
      "  230           Conv2d           4    [1536, 256, 1, 1]      [1, 1536, 8, 8]\n",
      "  231      BatchNorm2d           4               [1536]      [1, 1536, 8, 8]\n",
      "  232           Conv2d           4      [1536, 1, 1, 5]     [1, 768, 16, 16]\n",
      "  233      BatchNorm2d           4               [1536]     [1, 768, 16, 16]\n",
      "  234           Conv2d           4      [1536, 1, 5, 1]     [1, 768, 16, 16]\n",
      "  235      BatchNorm2d           4               [1536]     [1, 768, 16, 16]\n",
      "  236           Conv2d           4    [128, 1536, 1, 1]     [1, 128, 16, 16]\n",
      "  237      BatchNorm2d           4                [128]     [1, 128, 16, 16]\n",
      "  238           Conv2d           4       [128, 1, 3, 3]     [1, 128, 16, 16]\n",
      "  239      BatchNorm2d           4                [128]     [1, 128, 16, 16]\n",
      "  240           Conv2d           4     [768, 256, 1, 1]      [1, 1536, 8, 8]\n",
      "  241      BatchNorm2d           4                [768]      [1, 1536, 8, 8]\n",
      "  242           Conv2d           4       [768, 1, 3, 3]      [1, 1536, 8, 8]\n",
      "  243      BatchNorm2d           4                [768]      [1, 1536, 8, 8]\n",
      "  244           Conv2d           4    [1536, 256, 1, 1]      [1, 1536, 8, 8]\n",
      "  245      BatchNorm2d           4               [1536]      [1, 1536, 8, 8]\n",
      "  246           Conv2d           4      [1536, 1, 1, 5]     [1, 768, 16, 16]\n",
      "  247      BatchNorm2d           4               [1536]     [1, 768, 16, 16]\n",
      "  248           Conv2d           4      [1536, 1, 5, 1]     [1, 768, 16, 16]\n",
      "  249      BatchNorm2d           4               [1536]     [1, 768, 16, 16]\n",
      "  250           Conv2d           4    [384, 1536, 1, 1]       [1, 384, 1, 1]\n",
      "  251           Conv2d           4    [1536, 384, 1, 1]      [1, 1536, 1, 1]\n",
      "  252           Conv2d           4    [128, 1536, 1, 1]     [1, 128, 16, 16]\n",
      "  253      BatchNorm2d           4                [128]     [1, 128, 16, 16]\n",
      "  254           Conv2d           4       [128, 1, 3, 3]     [1, 128, 16, 16]\n",
      "  255      BatchNorm2d           4                [128]     [1, 128, 16, 16]\n",
      "  256           Conv2d           4    [1536, 256, 1, 1]    [1, 1536, 16, 16]\n",
      "  257      BatchNorm2d           4               [1536]    [1, 1536, 16, 16]\n",
      "  258           Conv2d           4    [192, 1536, 1, 1]     [1, 192, 16, 16]\n",
      "  259      BatchNorm2d           4                [192]     [1, 192, 16, 16]\n",
      "  260           Conv2d           4       [192, 1, 3, 3]     [1, 192, 16, 16]\n",
      "  261      BatchNorm2d           4                [192]     [1, 192, 16, 16]\n",
      "  262           Conv2d           4      [96, 384, 1, 1]        [1, 96, 1, 1]\n",
      "  263           Conv2d           4      [384, 96, 1, 1]       [1, 384, 1, 1]\n",
      "  264           Conv2d           4       [2, 384, 1, 1]       [1, 2, 16, 16]\n",
      "  265      BatchNorm2d           4                  [2]       [1, 2, 16, 16]\n",
      "  266           Conv2d           4         [2, 1, 3, 3]       [1, 2, 16, 16]\n",
      "  267      BatchNorm2d           4                  [2]       [1, 2, 16, 16]\n",
      "  268           Conv2d           4      [1536, 1, 3, 3]    [1, 1536, 16, 16]\n",
      "  269      BatchNorm2d           4               [1536]    [1, 1536, 16, 16]\n",
      "  270           Conv2d           4      [3, 1536, 1, 1]       [1, 3, 16, 16]\n",
      "  271      BatchNorm2d           4                  [3]       [1, 3, 16, 16]\n",
      "  272           Conv2d           4      [23, 180, 1, 1]      [1, 23, 32, 32]\n",
      "  273      BatchNorm2d           4                 [23]      [1, 23, 32, 32]\n",
      "  274           Conv2d           4        [23, 1, 3, 3]      [1, 23, 32, 32]\n",
      "  275      BatchNorm2d           4                 [23]      [1, 23, 32, 32]\n",
      "  276           Conv2d           4       [12, 45, 1, 1]        [1, 12, 1, 1]\n",
      "  277           Conv2d           4       [45, 12, 1, 1]        [1, 45, 1, 1]\n",
      "  278           Conv2d           4        [2, 45, 1, 1]       [1, 2, 32, 32]\n",
      "  279      BatchNorm2d           4                  [2]       [1, 2, 32, 32]\n",
      "  280           Conv2d           4         [2, 1, 3, 3]       [1, 2, 32, 32]\n",
      "  281      BatchNorm2d           4                  [2]       [1, 2, 32, 32]\n",
      "  282           Conv2d           4       [180, 1, 3, 3]     [1, 180, 32, 32]\n",
      "  283      BatchNorm2d           4                [180]     [1, 180, 32, 32]\n",
      "  284           Conv2d           4       [3, 180, 1, 1]       [1, 3, 32, 32]\n",
      "  285      BatchNorm2d           4                  [3]       [1, 3, 32, 32]\n",
      "  286           Conv2d           4        [8, 64, 1, 1]       [1, 8, 64, 64]\n",
      "  287      BatchNorm2d           4                  [8]       [1, 8, 64, 64]\n",
      "  288           Conv2d           4         [8, 1, 3, 3]       [1, 8, 64, 64]\n",
      "  289      BatchNorm2d           4                  [8]       [1, 8, 64, 64]\n",
      "  290           Conv2d           4        [4, 16, 1, 1]         [1, 4, 1, 1]\n",
      "  291           Conv2d           4        [16, 4, 1, 1]        [1, 16, 1, 1]\n",
      "  292           Conv2d           4        [2, 16, 1, 1]       [1, 2, 64, 64]\n",
      "  293      BatchNorm2d           4                  [2]       [1, 2, 64, 64]\n",
      "  294           Conv2d           4         [2, 1, 3, 3]       [1, 2, 64, 64]\n",
      "  295      BatchNorm2d           4                  [2]       [1, 2, 64, 64]\n",
      "  296           Conv2d           4        [64, 1, 3, 3]      [1, 64, 64, 64]\n",
      "  297      BatchNorm2d           4                 [64]      [1, 64, 64, 64]\n",
      "  298           Conv2d           4        [3, 64, 1, 1]       [1, 3, 64, 64]\n",
      "  299      BatchNorm2d           4                  [3]       [1, 3, 64, 64]\n",
      "==================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the datamodule\n",
    "datamodule = CoreDataModule(args, batch_size=128)\n",
    "\n",
    "# Define the trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100, callbacks=None, accelerator=\"auto\", precision=\"16-mixed\"\n",
    ")\n",
    "\n",
    "# Define the model\n",
    "model = ghostnetv2(\n",
    "    # num_classes=0,\n",
    "    error_model=\"single\",\n",
    "    inject_p=0.0001,\n",
    "    inject_epoch=0,\n",
    "    # ckpt=\"ckpt/GN_SSL_280.pt\",\n",
    ")\n",
    "model = GhostNetSS(model, SegmentationHeadGhostBN(), ckpt=args.ckpt)\n",
    "\n",
    "x = torch.randn(1, 5, 512, 512)\n",
    "y = model(x)\n",
    "print(y.shape)\n",
    "# print(intermediates[-1].shape)\n",
    "\n",
    "model = ModelWrapper(model=model)\n",
    "\n",
    "pfi_model = pfi_core.fault_injection(\n",
    "    model.cuda(),\n",
    "    1,\n",
    "    input_shape=[5, 512, 512],\n",
    "    layer_types=[\n",
    "        # torch.nn.Conv1d,\n",
    "        torch.nn.Conv2d,\n",
    "        # torch.nn.Conv3d,\n",
    "        torch.nn.BatchNorm1d,\n",
    "        torch.nn.BatchNorm2d,\n",
    "        torch.nn.BatchNorm3d,\n",
    "        # torch.nn.Linear,\n",
    "    ],\n",
    "    use_cuda=True,\n",
    ")\n",
    "pfi_model.print_pytorchfi_layer_summary()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blocks (12 to toggle): \n",
    "* ConvBnAct ✅\n",
    "* 9 Blocks ✅ ( consisting of 16 GhostBottleneckV2 sub-blocks) ❌\n",
    "* ConvBnAct ✅\n",
    "* AdaptiveAvgPool2d ❌\n",
    "* ConvAct ✅\n",
    "* Linear ❌\n",
    "\n",
    "\n",
    "Block Types (2 to toggle):\n",
    "* Conv2d ✅\n",
    "* BatchNorm2d ✅\n",
    "* Linear ❌\n",
    "\n",
    "inject_index (259 in total):\n",
    "* 137 Conv2d ✅\n",
    "* 122 BatchNorm2d ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d\n"
     ]
    }
   ],
   "source": [
    "csv_file = open(\"ckpt/ghostnetv2_layers.csv\", mode=\"r\")\n",
    "csv_reader = csv.reader(csv_file)\n",
    "layers = [row[0] for row in csv_reader]\n",
    "\n",
    "i = 100\n",
    "layer_type = layers[i]\n",
    "print(layer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training\n",
    "_ = trainer.validate(model=model, datamodule=datamodule)\n",
    "# print(intermediates[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_layers = []\n",
    "idx = 0\n",
    "for i, (name, desc) in enumerate(model.model.named_modules()):\n",
    "    n = name\n",
    "    t = str(type(desc)).split('.')[-1].split(\"'\")[0]\n",
    "    if t in [\"Conv2d\", \"BatchNorm2d\"]:\n",
    "        inj_layers.append((idx, t, i, n))\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv.writer(open(\"ckpt/ghostnetv2_clouds_layers_info.csv\", mode=\"w\")).writerows(inj_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(\"ckpt/GN_SSL_280.pt\")\n",
    "weights.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv\n",
    "from utils.utils import get_parser, parse_args\n",
    "\n",
    "parser, config_parser = get_parser()\n",
    "args = parse_args(parser, config_parser)\n",
    "\n",
    "reader = csv.reader(open(\"ckpt/layers_info.csv\", mode=\"r\"))\n",
    "layers = [{'inj_idx':inj_idx, 'layer_type':layer_type, 'model_idx':model_idx, 'layer_name':layer_name} for inj_idx, layer_type, model_idx, layer_name in reader]\n",
    "results = json.load(open(f\"ckpt/{args.name}_results.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (err, check) in results.items():\n",
    "    if check < 1e-6:\n",
    "        print(f\"{i} {layers[int(i)]['layer_type']} \\n  {layers[int(i)]['layer_name']} \\n  {err}\\n\")\n",
    "    else:\n",
    "        raise ValueError(f\"{layers[int(i)]} \\n{err} \\t {check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [int(i) for i, (err, _) in results.items() if layers[int(i)]['layer_type'] == \"Conv2d\"]\n",
    "y = [err for i, (err, _) in results.items() if layers[int(i)]['layer_type'] == \"Conv2d\"]\n",
    "plt.semilogy(x, y, label=f\"Conv: {sum(y)/len(y):.2e}\")\n",
    "x = [int(i) - 1 for i, (err, _) in results.items() if layers[int(i)]['layer_type'] == \"BatchNorm2d\"]\n",
    "y = [err for i, (err, _) in results.items() if layers[int(i)]['layer_type'] == \"BatchNorm2d\"]\n",
    "plt.semilogy(x, y, label=f\"BN: {sum(y)/len(y):.2e}\")\n",
    "# x = [int(i) for i, (err, _) in results.items()]\n",
    "# y = [check for i, (_, check) in results.items()]\n",
    "# plt.semilogy(x, y, label=\"BatchNorm2d\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Short Conv module is very robust to injection\n",
    "* BatchNorm2d is slightly less robust to injection than Conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.models.ghostnetv2 import ghostnetv2, SegmentationHeadGhostBN, GhostNetSS, load_fi_weights\n",
    "\n",
    "# Define the model\n",
    "backbone = ghostnetv2(\n",
    "    num_classes=0,\n",
    "    error_model=\"single\",\n",
    "    inject_p=0.0001,\n",
    "    inject_epoch=0,\n",
    "#     ckpt=\"ckpt/GN_SSL_280.pt\",\n",
    ")\n",
    "\n",
    "x = torch.randn(1, 5, 512, 512)\n",
    "y, intermediates = backbone(x)\n",
    "print(y.shape)\n",
    "print([inter.shape for inter in intermediates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = SegmentationHeadGhostBN()\n",
    "model = GhostNetSS(backbone, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_fi_weights(model, \"ckpt/bb_heads_clouds.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 5, 512, 512)\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From TIF file to numpy array\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "img_path = \"data/2021-09-01T10-00-00Z.tif\"\n",
    "\n",
    "# Open the images using rasterio\n",
    "with rasterio.open(img_path) as img:\n",
    "    b02 = img.read(2)  # Band 2 = Blue\n",
    "    b03 = img.read(3)  # Band 3 = Green\n",
    "    b04 = img.read(4)  # Band 4 = Red\n",
    "    b08 = img.read(8)  # Band 8 = NIR\n",
    "    b11 = img.read(11)  # Band 11 = SWIR1\n",
    "\n",
    "    # Stack the bands\n",
    "    img_image = np.stack([b02, b03, b04, b08, b11], axis=0).astype(np.float32)\n",
    "# From TIF file to numpy array\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "img_path = \"data/2021-09-01T10-00-00Z.tif\"\n",
    "\n",
    "# Open the images using rasterio\n",
    "with rasterio.open(img_path) as img:\n",
    "    b02 = img.read(2)  # Band 2 = Blue\n",
    "    b03 = img.read(3)  # Band 3 = Green\n",
    "    b04 = img.read(4)  # Band 4 = Red\n",
    "    b08 = img.read(8)  # Band 8 = NIR\n",
    "    b11 = img.read(11)  # Band 11 = SWIR1\n",
    "\n",
    "    # Stack the bands\n",
    "    img_image = np.stack([b02, b03, b04, b08, b11], axis=0).astype(np.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
